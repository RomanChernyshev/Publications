# С чего начинается Elasticsearch

![preview](https://i.ibb.co/7pCQyK6/dog.jpg)

Elasticsearch, вероятно, самая популярная поисковая система на данный момент с развитым сообществом, поддержкой и горой информации в сети. Однако эта информация поступает непоследовательно и дробно. Многие наступают на одни и те же грабли. 

Самое первое и главное заблуждение - "нужен поиск, так бери эластик!". Но в действительности, если вам нужен шустрый поиск для небольшого или даже вполне себе крупного проекта, вам стоит разобраться в теме поподробней и вы откажетесь от использования именно этой системы.

Вторая проблема заключается в том, что пытаясь разобраться с начала, получить общую картину окажется непросто. Да инфы навалом, но последовательность в ее изучении выстраивается постфактум. Придется из книг бежать в документацию, а из документации обратно в книги, параллельно разгугливая тонкости, только чтобы понять, что такое Elasticsearch, почему он работает именно так и для чего же его вообще использовать, а где стоит выбрать что-то попроще.

В этой статье я попытался последовательно объяснить то что мне кажется главным в Elasticsearch, то для чего он был придуман и как он устроен.

Для наглядности выдумаем себе задачу.  Реализация поиска в коллективном блоге по всем материалам и пользователям. Система позволяет создавать теги, сообщества, геометки и все остальные штуки, которые нам помогают категоризировать огромное количество информации.

## Схема хранения данных
**https://habr.com/ru/company/ruvds/blog/324936/**

https://tproger.ru/translations/sql-vs-nosql/

То, какие действия с данными мы будем производит определит схему их хранения:

- скорее всего поисковая система должна будет быстро производить поиск
- запись и удаление могут не отличаться высокой скоростью, в системах поиска, полагаю, этим можно пренебречь ЗАМЕНИТЬ НА БЫСТРУЮ ОБРАБОТКУ ДАННЫХ?
- структура данных будет интенсивно изменяться и хранилище может заполняться из нескольких независимых источников( различных баз, в том числе внешних для нашей системы )

Я НЕ СКАЗАЛ НИЧЕГО ПРО ТРАНЗАКЦИИ

Представьте еще раз сколько атрибутов может иметь публикация и сколько связанных с ней объектов. Автор, категория, сообщество, геометки, медиафайлы, теги, связанные публикации. Этот список можно продолжать до исчерпания фантазии. Если мы храним это в привычной реляционной базе то имеем миллион связей и миллиард атрибутов. Это прекрасно подходит для структурированного хранения долгие годы, но не очень вяжется с требованиями быстрого поиска. 

А что если мы захотим добавить пару интеграций с внешними системами? Придется реализовать дополнительные таблицы или даже базы. Нам всегда будет нужно что-то добавить или изменить в объектах доступных для поиска. Вы понимаете к чему я клоню.

Намного быстрее читать из объектов, содержащих все необходимое здесь и сейчас. И намного проще вносить изменения в неструктурированную схему данных.

![data schema](https://i.ibb.co/0nHggh8/Untitled-Diagram-5.png)

```json
{
    "title" : "С чего начинается Elasticsearch",
    "author" : {
        "name": "Roman"
    },
    "content" : "Elasticsearch, вероятно, самая популярная поисковая система...",
    "tags":[
        "elasticsearch"
    ],
    "ps": "Да, проще всего представить это как JSON, BSON или XML"
}
```

К тому же такие структуры данных проще делить, разносить по разным физическим хранилищам, распределять, ведь объекты уже содержат все необходимое.

Эти объекты мы можем воспринимать как отдельные страницы, файлы, карточки, все это можно назвать некими *документами*. Поэтому такая модель хранения данных называется *документоориентированной*.

> **Elasticsearch** это документоориентированная база данных
## Поиск(РЕДАКТИРОВАТЬ)
Теперь необходимо определиться с механизмами поиска. Данные организованы в виде документов. Как мы привыкли осуществлять поиск по документу? 

Типичным примером документа будет веб-страница. Если мы попытаемся поискать по всей странице в браузере, поиск будет осуществляться по всему содержащемуся тексту. И это удобно для большинства кейсов.

Примерно так же работают многие поисковые системы, поиск происходит по всему тексту проиндексированных страниц, а не по отдельным полям, тегам или заголовкам. Это называется *полнотекстовым* поиском.

Искать предстоит по огромному количеству документов и было бы разумно запомнить что в каком документе лежит. В реляционных СУБД мы привыкли оптимизировать подобный поиск индексами. 
Что такое индекс на самом деле? Если не вдаваться в детали, индекс это сбалансированное дерево, то есть дерево, в котором длина путей(количество шагов межу узлами) не будет отличаться больше чем на один шаг.

![B-tree](https://i.ibb.co/3p3KmhG/Untitled-Diagram-6.png)

Например если бы мы проиндексировали наш пост, то у нас бы получилось дерево, листьями которого, являлись бы используемые в нем слова. Простыми словами, мы будем знать заранее, какие слова находятся в документе и как их быстро в нем найти. Не смотря на такую удобную структуризацию данных, обход дерева звучит как не самое лучшее решение для максимально быстрого поиска.

А что если сделать все наоборот - собрать список всех используемых слов и узнать, в каких документах они встречаются. Да, индексация займет больше времени, но нас в первую очередь интересует именно скорость поиска, а не индексации.

<img src="https://i.ibb.co/1RMQ9wJ/Untitled-Diagram-7.png" alt="B-tree" style="zoom:50%;" />

Такой индекс называется *обратным индексом* и используется для полнотекстового поиска.

Хороший пример - популярная open-source библиотека полнотекстового поиска, конечно же, с обратным индексом, [Apache Lucene](https://lucene.apache.org/core/).

> **Elasticsearch** использует индексы Lucene для хранения данных и поиска

## Масштабирование(РЕДАКТИРОВАТЬ, СТРУКТУРИРОВАТЬ)
Как бы мы не пытались оптимизировать структуры данных и алгоритмы поиска, когда речь заходит о действительно больших массивах данных и действительно большом количестве запросов, необходимо задуматься о возможности повлиять на производительность системы путем увеличения аппаратного ресурса. Проще говоря, мы хотим иметь возможность накинуть немного памяти, ЦП и дискового пространства, чтобы все ехало быстрее. Мы можем назвать это *масштабируемостью*.

Самый простой вариант - накинуть железа на сервер. Если представить каждую условную единицу вычислительной мощности как деревянный кубик, то сейчас мы сложим кубики в одно место или один на другой, строя башню *вертикально*. Такое масштабирование и называется *вертикальным*.

Второй вариант - разделить наши задачи на группу машин. В этом случае мы тоже увеличиваем аппаратный ресурс, но сейчас кубики мы можем расположить на воображаемом столе как угодно на его плоскости, то есть *горизонтально*. Угадайте, как называется такое масштабирование?

Первый способ гарантирует нам быстрый результат без боли, но конечно не все так гладко. Как долго мы сможем увеличивать ресурс отдельной машины? Во-первых дешевым способом это будет только в самом начале, дальше оплата одного сервера будет стоить как несколько машин попроще. Во-вторых вы рано или поздно упретесь в потолок - железо, драйверы, пропускная способность и еще куча логических и физических ограничений. А самое главное, критический сбой в одной машине повлечет сбой всей системы, закономерно.

В отличии от первого способа второй не накладывает таких явных ограничений, мы можем добавлять машины сколько угодно, связывая их сетью. Конечно, это повлечет сетевые издержки - низкая скорость передачи в сети(в сравнении с обработкой на одной машине), сетевой оверхед. Но вместе с тем сеть имеет одно очень важное свойство - большую *отказоустойчивость*.

### Распределенный индекс
Ок, для хранения данных и поиска мы будем использовать инстанс Lucene. Но ранее мы решили, что для обеспечения горизонтального масштабирования нам необходимо иметь возможность размещать данные на разных машинах. В действительности, какая разница как данные хранятся физически? Важно чтобы мы имели единое логическое хранилище. Каждый инстанс Lucene должен стать частью одного большого индекса, или осколком(**shard**) разбитого индекса. Шард будет выполнять непосредственно операции по поиску и записи данных.

> **Shard** в **Elasticsearch** - это логическая единица хранения данных на уровне базы, которая является отдельным экземпляром Lucene.
>
> **Index** - это одновременно и распределенная база и механизм управления и организации данных, это именно логическое пространство. Индекс содержит один или более шардов, их совокупность и является хранилищем.
>
> Классическое сравнение индекса с другими базами выглядит примерно так.
>
> | **Elasticsearch** | **SQL**  | **MongoDB**  |
> | ----------------- | -------- | ------------ |
> | Index             | Database | Database     |
> | Mapping/Type      | Table    | Collection   |
> | Field             | Column   | Field        |
> | Object(JSON)      | Tuple    | Object(BSON) |
>
> Но существуют отличия в использовании этих абстракций. Рассмотрим еще один классический пример. У пользователя системы может храниться очень много информации, и мы решаем создавать новую базу для каждого пользователя. Это звучит дико! Но на самом деле в Elasticsearch это распространенная и даже хорошая практика. Индекс это довольно легкий механизм и лучше разделять большие данные, тем более, когда это логически оправдано. Системе проще работать с небольшими индексами чем с разросшейся базой для всего. Например, так вы можете создавать отдельный индекс для логов на каждый день и это широко используется.
>
> По умолчанию количество шардов для индекса будет равным 5, но его всегда возможно изменить в настройках `index.number_of_shards: 1` или с помощью запроса шаблонов индекса.
>
> ```json
> PUT _template/all
> {
>   "template": "*",
>   "settings": {
>     "number_of_shards": 1
>   }
> }
> ```
>
> Важно управлять этим значением. Всегда принимайте решения с точки зрения параллельной обработки. 
>
> Каждый шард способен хранить примерно 2<sup>32</sup>  или 4294967296 записей, это значит, что скорее всего вы упретесь в лимит вашего диска. Однако стоит понимать, все шарды будут участвовать в поиске и если мы будем искать по сотне пустых, потратим время впустую. Если шарды будут слишком большими мы так же будем тратить лишнее время на поиск, а так же операций перемещения и индексации станут очень тяжелыми.
>
> Забегая вперед. Со временем Elasticsearch двигает и изменяет шарды, объединяя дробные и мелкие в большие. Следите за размером ваших шардов, при достижении 10ГБ производительность значительно падает.

### Ноды

Так помимо хранения данных нужно решить, как управлять *кластером* . Откуда взять и куда положить? 

> **Cluster** это сеть из всех запущенных экземпляров **Elasticsearch** с одинаковым идентификатором кластер

Отличной идеей было бы поднять один такой экземпляр, который помимо хранения данных взял бы на себя управление. Такие ноды называются мастер-нодами.

> **Master-node**  в **Elasticsearch**  - это узел, для которого настройка `node.master` установлена значение `true`(по умолчанию), что позволяет ему быть [избранным в качестве *главного* узла](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery.html) , управляющего кластером.

Мастер-ноды всегда знают, что происходит в кластере, они могут выполнять роль координирующих узлов. Мастер выполняет довольно легкие но важные общекластерные действия, а значит требует стабильности. Поэтому следует избавить мастера от выполнения работы с индексом, так как это может потребовать значительных затрат ресурса машины.

Ок, если у нас есть управляющие мастер-ноды, тогда пусть будут и управляемые ноды. Например, для хранения данных, конечно. Они называются дата-нодами.

> **Data-node**  в **Elasticsearch**  содержат *шарды*, с проиндексированными документами. Узлы данных обрабатывают связанные с данными операции, такие как CRUD, поиск и агрегации. 

Операции с данными требуют интенсивного ввода-вывода, а значит быстрого диска, памяти и ЦП от машины. Важно отслеживать эти ресурсы и добавлять больше узлов данных, если они перегружены.

Мастер так же может выполнять работу по балансировке данных наших дата-нод, не нагружать созданием лишних шардов и без того нагруженные дата-ноды или даже перемещать шарды между ними, так же выбирать для определенного индекса определенные ноды.

Для того, чтобы узнать состояние дата-нод, выполнить поиск или другие операции используется модель **MapReduce**. На шаге *map* координирующий узел предварительно обрабатывает запрос, формулирует задачу для worker-нод( в нашем случае это дата-ноды ) и отправляет запрос им. Worker-ноды выполняют определенную работу и отправляют результат координирующему узлу.  Далее выполняется шаг *reduce*,  на основе результатов формируется окончательный ответ для клиента. Так мы можем распараллелить тяжелые операции с индексом.

### Репликация данных

Арчибальд уже выкатил первый прототип поисковой системы и пришло время задуматься *высокой доступности* .  Речь идет о том, что мы не можем себе позволить потерять данные. Что если по какой-то причине отпадет дата-нода?

Репликация. Данные должны быть доступны как минимум из двух независимых мест.

> В Elasticsearch несколько нод можно поднять на одной машине, для этого они должны быть запущенны из разных директорий. Это помогает при создании, тестировании и настройке кластера, однако в проде следует выделять отдельную машину под каждую ноду.
>
> Чтобы жестко установить количество реплик индекса используется параметр `number_of_replicas` . Так же мы можем изменить это значение в рантайме выполнив запрос:
>
> ```json
> PUT / _settings {
> 	"index": {
> 		"number_of_replicas": someVal
> 	}
> }
> ```

То есть для каждого шарда должна быть как минимум одна копия на другой ноде. Можно конечно выделять по отдельной машине для каждой реплики, но это очень расточительно. Нужно разместить копии данных на разных нодах, но это не значит, что эти ноды должны хранить только шарды реплик. 

ТУТ ДОЛЖНА БЫТЬ КАРТИНКА 

Таким образом мы всегда имеем реплики всех шардов и не поднимаем неэффективно простаивающие ноды. 

> В Elasticsearch основной шард называется первичным( *primary shard* ), реплика же называется реплицирующим шардом( *replica shard* ). Первичный шард и его реплики это группа репликации.

Но какова же механика репликации?

Сперва данные, очевидно должны быть записаны в первичный шард, и только после того как это произойдет можно начать последовательное копирование на реплики. В этом случае потери данных   при сбое ограничены одной записью.

> Для мониторинга состояния кластера в Elasticsearch существует *cluster health status*. Статус может иметь три значения: `green`, `yellow` или `red`.  `green`- все ок. `yellow` - есть утраченные шарды, кластер полностью работоспособен, но едет на репликах. `red`- есть утраченные шарды, кластер неработоспособен или часть данных недоступна. 

В случае утери первичного шарда кластер автоматически должен понять, что ему нужно использовать соответствующую реплику. Как только утерянная нода вернется в строй, выполнится синхронизация и ее шард снова станет первичным.

Для максимальной стабильности кластера необходимо, чтобы количество дата-нод было больше или равно количества реплик.

### Отказоустойчивость

Сейчас данные будут доступны даже в случае сбоя одного из хранящих узлов. Но что если сбой случится в управляющем узле?

Арчибальд быстро находит решение в введении в систему дополнительных мастер-нод. Если отвалится один мастер, то работу продолжит другой.

Но если у нас есть, например, два управляющих узла, как понять, какой из них в данный момент должен управлять кластером? Как они смогут договориться о своих решениях? Очевидно, что в каждый момент времени должен быть только один управляющий кластером узел.

Тогда пусть, на старте выберется один мастер и кандидаты на его должность.

> Поэтому в Elasticsearch настройка `node.master: true ` не будет означать, что данный узел является мастером, это всего лишь скажет о том, что он может быть выбран в качестве главного узла. По умолчанию настройки будут установлены следующим образом:
>
> - `node.master: true`
> - `node.data: true`

Почему следует оставить возможность поднимать в дата-ноды, которые могут быть выбраны в качестве главного?

Потому, что ситуация с потерей мастера является исключительной, в такой ситуации резервный мастер должен взять на себя управление и сохранить доступность системы. То есть мы можем пожертвовать скоростью резервной мастер-ноды на период восстановления отвалившейся ноды. Это способ сэкономить затраты на поддержание резервных узлов и один из вариантов использования кластера. Если необходима максимальная отказоустойчивость без потерь в скорости выполнения, тогда придется поднять отдельные only-master узлы, ожидающие своего часа на скамейке запасных.

Определившись с концепцией *выбора* мастер-ноды, перед Арчибальдом встает еще один вопрос. Как именно должен происходить выбор мастера?

Представим. Главный управляющий узел стал недоступен для кластера, кластер берет первого кандидата и устанавливает его на вакантное место. Вроде бы все ок. Но спустя определенное время первый мастер возвращается в кластер и ничего не знает о том, что его место уже занято. Мастер-ноды являются управляющими центрами кластера, своего рода его *мозгом*, и теперь мозг кластера становится разделен. Это классическая проблема распределенных систем и она так и называется *split-brain problem*.

В обществе подобные проблемы зачастую решаются путем голосования. Подобный механизм используется и в распределенных системах. Как только кластер теряет управляющий узел, должен быть запущен процесс голосования.

Важно определить какой из кандидатов больше всего подходит на роль главного узла. Такой кандидат должен обладать самой актуально информацией о кластере. Для краткого описания актуальности информации о кластере может использоваться версионирование. При каждом изменении кластера будет главный узел будет обновлять некую служебную информацию и повышать номер версии, далее то же самое будет параллельно происходить в нодах-кандидатах.

Сравнив номера версий мы можем определить наиболее подходящих кандидатов на роль мастера. Теперь если отпавшая мастер-нода вернется в кластер, то процесс голосования запустится снова и будет выбран единственный управляющий узел.

ТУТ КАРТИНКА ВЫБОРОВ

Теперь важно понять когда можно считать, что голосование прошло успешно? Если проголосовали все участники? Или половина? Или другое любое другое магическое количество?

Решение этой проблемы заключается в определении *кворума*. Это умное название для контрольного количества голосующих.

Очевидно, что такое важное решение как выбор мастера должно приниматься на основе большинства, то есть 50%+один голос. Справедливо, надежно. Это значение и станет кворумом.

Таким образом количество кандидатов на мастера должно быть нечетным и не меньше трех. Рекомендуется использовать простую формулу для расчета оптимально количества таких нод:

`КОЛИЧЕСТВО_КАНДИДАТОВ = ОБЩЕЕ_КОЛИЧЕСТВО_НОД/2 + 1`.

> Elasticsearch автоматически изменяет конфигурацию голосования при изменении кластера. Поэтому нельзя одновременно отключать половину или более голосующих нод. Например, если  в вашей конфигурации в данный момент 7 голосующих нод и вы отключили сразу 4, кластер станет недоступным, потому что останется 3 ноды, а в конфигурации голосования кворумом является значение 4.

